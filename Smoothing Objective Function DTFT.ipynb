{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from utils.neural_network import train_nn, get_device, batch_data_by_country\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing_v2 import Preprocessing, get_gt_diff_logs\n",
    "import utils.results as results\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROPORTION = 0.9\n",
    "PERIOD = 4  # Year to year prediction\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_gdps, all_gts = load_data()\n",
    "data['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing(epsilon=EPS, gdp_diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, x_hf = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION, \n",
    "                                                                  mode=\"diff\", \n",
    "                                                                  take_log_diff_gdp=True,\n",
    "                                                                  gt_trend_removal=False, \n",
    "                                                                  keep_pca_components=180, \n",
    "                                                                  #noisy_data_stds=[0.005, 0.05, 0.1], \n",
    "                                                                  add_encoded_month=False, \n",
    "                                                                  gt_data_transformations=[get_gt_diff_logs], other_params={'plot_pca': False})\n",
    "\n",
    "x_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "x_valid_t = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device)\n",
    "x_hf_t = torch.tensor(x_hf, dtype=torch.float32).to(device)\n",
    "\n",
    "print(all_gts['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.dates_high_freq\n",
    "preprocessor.country_high_freq\n",
    "\n",
    "df_hf = pd.DataFrame({\n",
    "    'date': preprocessor.dates_high_freq,\n",
    "    'country': preprocessor.country_high_freq,\n",
    "    'data': [x_hf[i] for i in range(len(x_hf))]\n",
    "})\n",
    "\n",
    "df_x_train = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train.copy(),\n",
    "    'country': preprocessor.country_train.copy(),\n",
    "    'data': [X_train[i].copy() for i in range(len(X_train))],\n",
    "    'y_true': [y_train[i].copy() for i in range(len(y_train))]\n",
    "})\n",
    "\n",
    "df_hf['date'] = pd.to_datetime(df_hf['date'])\n",
    "df_x_train['date'] = pd.to_datetime(df_x_train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model, basic_training_loss, basic_validation_loss, basic_validation_r_squared, basic_global_mse_losses = train_nn(X_train, \n",
    "                                                                        y_train, \n",
    "                                                                        X_valid, \n",
    "                                                                        y_valid, \n",
    "                                                                        num_epochs=100, \n",
    "                                                                        learning_rate=1e-4, \n",
    "                                                                        weight_decay=1e-2, \n",
    "                                                                        verbose=True,\n",
    "                                                                        seed=SEED)\n",
    "\n",
    "# Get the predictions\n",
    "basic_y_pred_hf = basic_model(torch.tensor(x_hf, dtype=torch.float32).to(device)).clone().detach().cpu().numpy().squeeze()\n",
    "basic_y_pred_lf = basic_model(torch.cat((x_train_t, x_valid_t), 0)).clone().detach().cpu().numpy().squeeze()\n",
    "basic_r2_score = results.r2_score(y_valid, basic_model(x_valid_t).clone().detach().cpu().numpy().squeeze())\n",
    "\n",
    "print(f\"Basic R2 score: {basic_r2_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Fourrier Transform Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_hf = pd.DataFrame({\n",
    "    'date': preprocessor.dates_high_freq,\n",
    "    'country': preprocessor.country_high_freq,\n",
    "    'data': [basic_y_pred_hf[i] for i in range(len(basic_y_pred_hf))] \n",
    "})\n",
    "\n",
    "def fft_analysis(preds, cutoff=0.05): \n",
    "    fft = np.fft.fft(preds)\n",
    "    freqs = np.fft.fftfreq(len(preds))\n",
    "\n",
    "    filtered = np.copy(fft)\n",
    "    filtered[np.abs(freqs) > cutoff] = 0\n",
    "\n",
    "    y_filtered = np.fft.ifft(filtered).real\n",
    "\n",
    "    smoothness_loss = np.linalg.norm(y_filtered - preds) ** 2 / len(preds)\n",
    "\n",
    "    plt.plot(preds, label='Original')\n",
    "    plt.plot(y_filtered, label='Filtered')\n",
    "    plt.title(f\"FFT Analysis (cutoff={cutoff}) - Smoothness Loss: {smoothness_loss}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Per country\n",
    "for country in df_preds_hf['country'].unique()[:2]:\n",
    "    country_data = df_preds_hf[df_preds_hf['country'] == country]\n",
    "    fft_analysis(country_data['data'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_upsample(signal, upsample_factor):\n",
    "    if upsample_factor < 1:\n",
    "        raise ValueError(\"Upsample factor must be greater than 1.\")\n",
    "    \n",
    "    # Original signal length\n",
    "    N = len(signal)\n",
    "\n",
    "    # Energy to 1\n",
    "    # orig_energy = np.linalg.norm(signal)\n",
    "    signal = signal\n",
    "    \n",
    "    # Compute the Fourier Transform of the signal\n",
    "    fft_signal = np.fft.fft(signal) / np.sqrt(N)\n",
    "    \n",
    "    # High-pass filter the signal\n",
    "    fft_freqs = np.fft.fftfreq(N)\n",
    "    #fft_signal[np.abs(fft_freqs) > 0.15] = 0\n",
    "    \n",
    "    # Zero-pad the FFT to increase resolution\n",
    "    pad_size = (upsample_factor - 1) * N // 2\n",
    "    fft_signal_padded = np.concatenate([\n",
    "        fft_signal[:N // 2],                # Low frequencies\n",
    "        np.zeros(pad_size),                # Zero-padding\n",
    "        fft_signal[N // 2:]                # High frequencies\n",
    "    ])\n",
    "\n",
    "    # Perform the Inverse FFT to return to the time domain\n",
    "    upsampled_signal = np.fft.ifft(fft_signal_padded).real\n",
    "\n",
    "    # Scale the result to adjust for energy conservation\n",
    "    upsampled_signal *= np.sqrt(N) * upsample_factor\n",
    "\n",
    "    \n",
    "    return upsampled_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_using_fft(signal, cutoff=0.1):\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal))\n",
    "\n",
    "    fft_signal[np.abs(freqs) > cutoff] = 0\n",
    "\n",
    "    return np.fft.ifft(fft_signal).real\n",
    "\n",
    "def smooth_upsampled(signal, upsample_factor, cutoff=0.1):\n",
    "    upsampled = resample(signal[:-1], upsample_factor * len(signal))\n",
    "    upsampled = np.concatenate([upsampled, [signal[-1]]])\n",
    "\n",
    "    if cutoff is None:\n",
    "        return upsampled\n",
    "    \n",
    "    smoothed = smooth_using_fft(upsampled, cutoff)\n",
    "\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_gdps = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train,\n",
    "    'country': preprocessor.country_train,\n",
    "    'data': [y_train[i] for i in range(len(y_train))]\n",
    "})\n",
    "\n",
    "for country in df_preds_hf['country'].unique()[:]:\n",
    "    if country == 'Japan':\n",
    "        continue\n",
    "\n",
    "    country_data = df_preds_hf[df_preds_hf['country'] == country]\n",
    "\n",
    "    signal = country_data['data'].values    \n",
    "    new_sig = smooth_upsampled(signal, 3, cutoff=0.03)\n",
    "\n",
    "    x = np.linspace(0, 1, len(new_sig))\n",
    "    orig_x = np.linspace(0, 1, len(country_data['data'].values))\n",
    "\n",
    "    plt.plot(orig_x, country_data['data'].values, label='Original')\n",
    "    plt.plot(x, new_sig, label='Upsampled Smooth')\n",
    "\n",
    "    # Real gdps\n",
    "    X_train_country = df_true_gdps[df_true_gdps['country'] == country]\n",
    "    plt.plot(np.linspace(0, 3 * len(X_train_country['data']) / len(country_data['data'].values), len(X_train_country['data'])), X_train_country['data'], label='Real GDP')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f\"Country: {country}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true_gdps = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train,\n",
    "    'country': preprocessor.country_train,\n",
    "    'data': [y_train[i] for i in range(len(y_train))]\n",
    "})\n",
    "\n",
    "for country in df_preds_hf['country'].unique()[:3]:\n",
    "    country_data = df_true_gdps[df_true_gdps['country'] == country]\n",
    "\n",
    "    signal =  country_data['data'].values   \n",
    "    new_sig = smooth_upsampled(signal, 1, cutoff=None)#0.2)\n",
    "\n",
    "    x = np.linspace(0, 1, len(new_sig))\n",
    "    orig_x = np.linspace(0, 1, len(country_data['data'].values))\n",
    "\n",
    "    plt.plot(orig_x, country_data['data'].values, label='Original')\n",
    "    plt.plot(x, new_sig, label='Upsampled')\n",
    "    plt.legend()\n",
    "\n",
    "    # Real gdps\n",
    "    # X_train_country = df_true_gdps[df_true_gdps['country'] == country]\n",
    "    # plt.plot(np.linspace(0, 3 * len(X_train_country['data']) / len(country_data['data'].values), len(X_train_country['data'])), X_train_country['data'], label='Real GDP')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
