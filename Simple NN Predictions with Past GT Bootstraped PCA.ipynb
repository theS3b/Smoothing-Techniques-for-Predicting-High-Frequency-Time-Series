{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing import Preprocessing\n",
    "from utils.results import compute_rsquared\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ALL_GT_DATA = False # If set to True, the model will be trained on all available data and predictions will be made for all available GT data\n",
    "\n",
    "TRAIN_PROPORTION = 0.9 if not TEST_ALL_GT_DATA else 1\n",
    "PAST_GDPS = [] if not TEST_ALL_GT_DATA else None # e.g. range(1, 3) or [1, 2]\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 4  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_gdps, all_gts = load_data()\n",
    "search_terms = [col for col in all_gts.columns if col.endswith('_average')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_gts = all_gts.copy() # Monthly Google Trends\n",
    "processed_gts['date'] = pd.to_datetime(processed_gts['date'])\n",
    "processed_gts[search_terms] = np.log(processed_gts[search_terms] + 1)\n",
    "\n",
    "for nb_years in range(1, 3): # 3 will add 2 years difference\n",
    "    diff = (processed_gts[search_terms] - processed_gts.groupby(\"country\")[search_terms].diff(nb_years * 12)).add_suffix(f'_{nb_years}y_diff')\n",
    "    processed_gts = pd.concat([processed_gts, diff], axis=1)\n",
    "\n",
    "processed_gts.drop(columns=search_terms, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (550, 97)\n",
      "Data merged shape: (550, 285)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "processed_gts = processed_gts.dropna()\n",
    "data_merged = data.merge(processed_gts, left_on=[\"country\", \"date\"], right_on=[\"country\", \"date\"], how=\"left\")\n",
    "data_merged['date'] = pd.to_datetime(data_merged['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Data merged shape: {data_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>country</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006-03-01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>44119.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Expense_average      country      GDP\n",
       "8 2006-03-01             45.0  Switzerland  44119.1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['country'] == 'Switzerland') & (data['date'] == '2006-03-01')][[col for col in data.columns if 'GDP' in col or 'Expense_' in col or 'date' in col or 'country' in col]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dt = data_merged.copy()\n",
    "data_dt['date'] = pd.to_datetime(data_dt['date'])\n",
    "splitting_date = data_dt['date'].quantile(TRAIN_PROPORTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-03-01 00:00:00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (414, 292)\n",
      "X_valid shape : (60, 292)\n",
      "y_train shape : (414,)\n",
      "y_valid shape : (60,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>Credit_average</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Korea</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.049943</td>\n",
       "      <td>-1.234660</td>\n",
       "      <td>-1.975457</td>\n",
       "      <td>1.390782</td>\n",
       "      <td>-1.558854</td>\n",
       "      <td>0.877317</td>\n",
       "      <td>-0.615793</td>\n",
       "      <td>1.337631</td>\n",
       "      <td>-1.359529</td>\n",
       "      <td>1.387799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.38683</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>2.426056</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.634628</td>\n",
       "      <td>-1.454471</td>\n",
       "      <td>-1.975457</td>\n",
       "      <td>1.526349</td>\n",
       "      <td>-1.433511</td>\n",
       "      <td>-0.740511</td>\n",
       "      <td>-0.615793</td>\n",
       "      <td>1.702391</td>\n",
       "      <td>-1.448770</td>\n",
       "      <td>1.210783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.38683</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>2.426056</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.049943</td>\n",
       "      <td>-0.721767</td>\n",
       "      <td>-1.975457</td>\n",
       "      <td>1.221325</td>\n",
       "      <td>-1.370839</td>\n",
       "      <td>-1.026010</td>\n",
       "      <td>-0.615793</td>\n",
       "      <td>0.681062</td>\n",
       "      <td>-0.913322</td>\n",
       "      <td>1.255037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.38683</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>2.426056</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.422015</td>\n",
       "      <td>-1.307930</td>\n",
       "      <td>-1.975457</td>\n",
       "      <td>0.645168</td>\n",
       "      <td>-1.621525</td>\n",
       "      <td>-0.890058</td>\n",
       "      <td>-0.615793</td>\n",
       "      <td>1.264679</td>\n",
       "      <td>-0.913322</td>\n",
       "      <td>0.281451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.38683</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>2.426056</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.315709</td>\n",
       "      <td>-1.674282</td>\n",
       "      <td>-1.975457</td>\n",
       "      <td>0.950192</td>\n",
       "      <td>-1.245497</td>\n",
       "      <td>1.652243</td>\n",
       "      <td>-0.615793</td>\n",
       "      <td>1.629439</td>\n",
       "      <td>-1.627253</td>\n",
       "      <td>1.122275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.38683</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>2.426056</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>-0.411196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Expense_average  Research_and_development_average  \\\n",
       "1         -0.049943                         -1.234660   \n",
       "7         -0.634628                         -1.454471   \n",
       "16        -0.049943                         -0.721767   \n",
       "22        -0.422015                         -1.307930   \n",
       "27        -0.315709                         -1.674282   \n",
       "\n",
       "    Capital_expenditure_average  Business_average  Cost_average  Tax_average  \\\n",
       "1                     -1.975457          1.390782     -1.558854     0.877317   \n",
       "7                     -1.975457          1.526349     -1.433511    -0.740511   \n",
       "16                    -1.975457          1.221325     -1.370839    -1.026010   \n",
       "22                    -1.975457          0.645168     -1.621525    -0.890058   \n",
       "27                    -1.975457          0.950192     -1.245497     1.652243   \n",
       "\n",
       "    Financial_capital_average  Investment_average  \\\n",
       "1                   -0.615793            1.337631   \n",
       "7                   -0.615793            1.702391   \n",
       "16                  -0.615793            0.681062   \n",
       "22                  -0.615793            1.264679   \n",
       "27                  -0.615793            1.629439   \n",
       "\n",
       "    Gross_domestic_product_average  Credit_average  ...  country_Germany  \\\n",
       "1                        -1.359529        1.387799  ...        -0.411196   \n",
       "7                        -1.448770        1.210783  ...        -0.411196   \n",
       "16                       -0.913322        1.255037  ...        -0.411196   \n",
       "22                       -0.913322        0.281451  ...        -0.411196   \n",
       "27                       -1.627253        1.122275  ...        -0.411196   \n",
       "\n",
       "    country_Japan  country_Korea  country_Switzerland  country_United Kingdom  \\\n",
       "1        -0.38683      -0.411196             2.426056               -0.411196   \n",
       "7        -0.38683      -0.411196             2.426056               -0.411196   \n",
       "16       -0.38683      -0.411196             2.426056               -0.411196   \n",
       "22       -0.38683      -0.411196             2.426056               -0.411196   \n",
       "27       -0.38683      -0.411196             2.426056               -0.411196   \n",
       "\n",
       "    country_United States  month_3  month_6  month_9  month_12  \n",
       "1               -0.411196      1.0      0.0      0.0       0.0  \n",
       "7               -0.411196      0.0      1.0      0.0       0.0  \n",
       "16              -0.411196      0.0      0.0      1.0       0.0  \n",
       "22              -0.411196      0.0      0.0      0.0       1.0  \n",
       "27              -0.411196      1.0      0.0      0.0       0.0  \n",
       "\n",
       "[5 rows x 292 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessing(data=data_merged.dropna(), epsilon=EPS, mode=MODE, past_GDP_lags=PAST_GDPS, diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION, shuffle=False, splitting_date=splitting_date)\n",
    "\n",
    "X_train[preprocessor.country_train == \"Switzerland\"].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1.753144</td>\n",
       "      <td>2021-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>3.037288</td>\n",
       "      <td>2021-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.958372</td>\n",
       "      <td>2021-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.955891</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.818444</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.842828</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2.237596</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.268288</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2.973334</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1.048175</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GDP       date\n",
       "404  1.753144 2021-09-01\n",
       "405  3.037288 2021-09-01\n",
       "406  0.958372 2021-09-01\n",
       "407  2.955891 2021-12-01\n",
       "408  1.818444 2021-12-01\n",
       "409  0.842828 2021-12-01\n",
       "410  2.237596 2021-12-01\n",
       "411  0.268288 2021-12-01\n",
       "412  2.973334 2021-12-01\n",
       "413  1.048175 2021-12-01"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([y_train, preprocessor.dates_train], axis=1)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Research_and_development_average', 'Research_and_development_average_1y_diff', 'Research_and_development_average_2y_diff'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df = np.concatenate([X_train, preprocessor.dates_train], axis=1)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train, preprocessor\u001b[38;5;241m.\u001b[39mdates_train], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountry_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSwitzerland\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Research_and_development_average', 'Research_and_development_average_1y_diff', 'Research_and_development_average_2y_diff'] not in index\""
     ]
    }
   ],
   "source": [
    "# Print all columns that contain Research_and_development\n",
    "search_term = \"Research_and_development\"\n",
    "search_cols = [col for col in X_train.columns if search_term in col]\n",
    "other_cols = []\n",
    "\n",
    "# df = np.concatenate([X_train, preprocessor.dates_train], axis=1)\n",
    "df = pd.concat([X_train, preprocessor.dates_train], axis=1)\n",
    "\n",
    "df[(preprocessor.country_train == \"Switzerland\")][search_cols + other_cols + [\"date\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(preprocessor.country_train == \"Switzerland\")][search_cols + other_cols + [\"date\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "pca = PCA(150)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_valid_pca = pca.transform(X_valid)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum()}\")\n",
    "plot.figure(figsize=(10, 6))\n",
    "plot.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Plot singular values\n",
    "plot.figure(figsize=(10, 6))\n",
    "plot.plot(pca.singular_values_)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = X_train.values\n",
    "# x_valid = X_valid.values\n",
    "x_train = X_train_pca\n",
    "x_valid = X_valid_pca\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "country_train = preprocessor.country_train\n",
    "country_valid = preprocessor.country_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "# Function to set random seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch for all GPUs (if multiple GPUs are used)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic optimizations\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=2000, learning_rate=1e-3, weight_decay=1e-3, verbose = True):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    valid_r_squared = []\n",
    "    \n",
    "    epoch_range = tqdm(range(num_epochs)) if verbose else range(num_epochs)\n",
    "    for t in epoch_range:\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "\n",
    "        valid_r_squared.append(r_squared)\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "\n",
    "    v_loss = loss_fn(y_pred, y_valid_t)\n",
    "    validation_loss.append(v_loss.item())\n",
    "    print(f\"Validation loss: {v_loss.item()}\")\n",
    "\n",
    "    t_loss = loss_fn(model(x_train_t), y_train_t)\n",
    "    training_loss.append(t_loss.item())\n",
    "    print(f\"Training loss: {t_loss.item()}\")\n",
    "\n",
    "    r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "    valid_r_squared.append(r_squared)\n",
    "    print(f\"Validation R^2: {r_squared}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss, valid_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss, validation_r_squared = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=300, learning_rate=1e-3, weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.plot(validation_r_squared, label=\"Validation R^2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bootrapping\n",
    "n_bootstrap = 250\n",
    "n = len(x_train)\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "n_countries = len(np.unique(country_train))\n",
    "\n",
    "bootstrap_size = n // n_countries # np.ceil(150 / n_countries).astype(int)\n",
    "\n",
    "bootstrap_models = []\n",
    "mse_bootstrap = np.zeros(n_bootstrap)\n",
    "rsquared_bootstrap = np.zeros(n_bootstrap)\n",
    "\n",
    "for i in tqdm(range(n_bootstrap)):\n",
    "    # Make a bootstrap sample of size bootstrap_size\n",
    "    set_seed(SEED + i)\n",
    "\n",
    "    indices_per_country = [np.where(country_train == c)[0] for c in np.unique(country_train)]\n",
    "    bootstrap_idx = np.concatenate([np.random.choice(indices, size=bootstrap_size, replace=True) for indices in indices_per_country])\n",
    "    x_train_bootstrap = x_train[bootstrap_idx]\n",
    "    y_train_bootstrap = y_train[bootstrap_idx]\n",
    "\n",
    "    model_bootstrap, _, _, _ = train_nn(x_train_bootstrap, y_train_bootstrap, x_valid, y_valid, num_epochs=50, learning_rate=1e-3, weight_decay=5e-2, verbose=False)\n",
    "    y_pred = model_bootstrap(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rsquared = compute_rsquared(y_valid, y_pred)\n",
    "\n",
    "    bootstrap_models.append(model_bootstrap)\n",
    "    mse_bootstrap[i] = mse\n",
    "    rsquared_bootstrap[i] = rsquared\n",
    "\n",
    "# Aggregate the predictions\n",
    "y_pred = np.zeros((x_valid.shape[0], n_bootstrap))\n",
    "for i in range(n_bootstrap):\n",
    "    y_pred[:, i] = bootstrap_models[i](torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "y_pred_mean = np.mean(y_pred, axis=1)\n",
    "y_pred_std = np.std(y_pred, axis=1)\n",
    "y_pred_median = np.median(y_pred, axis=1)\n",
    "\n",
    "# Get the model with the best R squared\n",
    "best_model_idx = np.argmax(rsquared_bootstrap)\n",
    "best_model = bootstrap_models[best_model_idx]\n",
    "best_rsquared = rsquared_bootstrap[best_model_idx]\n",
    "y_pred_best = best_model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(mse_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the r squared\n",
    "bootstrapped_r2 = compute_rsquared(y_valid, y_pred_mean)\n",
    "print(f\"Bootstrapped R^2: {bootstrapped_r2}\")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(rsquared_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"R squared\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions per country, per date\n",
    "def plot_by_country(selected_country):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(y_valid[country_valid == selected_country], label=\"True\")\n",
    "    plt.plot(y_pred_mean[country_valid == selected_country], label=\"Predicted\")\n",
    "    plt.plot(y_pred_median[country_valid == selected_country], label=\"Predicted (median)\")\n",
    "    plt.plot(y_pred_best[country_valid == selected_country], label=\"Predicted (best)\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 3 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 3 * y_pred_std[country_valid == selected_country], alpha=0.05, color=\"red\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 1.96 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 1.96 * y_pred_std[country_valid == selected_country], alpha=0.2)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"GDP\")\n",
    "    plt.title(f\"{selected_country}\")\n",
    "    plt.legend()\n",
    "\n",
    "interact(plot_by_country, selected_country=np.unique(country_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BASED ONLY ON THE FIRST MODEL !! NOT THE BOOTSTRAP MODELS\n",
    "\n",
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country and add 'Set' column\n",
    "y_pred_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_valid,\n",
    "    'country': country_valid,\n",
    "    'y_pred': y_pred,\n",
    "    'y_true': y_valid,\n",
    "    'Set': 'Validation'\n",
    "})\n",
    "\n",
    "y_pred_train_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train,\n",
    "    'country': country_train,\n",
    "    'y_pred': y_pred_train,\n",
    "    'y_true': y_train,\n",
    "    'Set': 'Training'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None, style=\"Set\", markers=True\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[(predictions_melted[\"country\"] == selected_country) & (predictions_melted[\"Set\"] == \"Validation\")]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
