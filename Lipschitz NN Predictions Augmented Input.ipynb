{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.load_data import load_data\n",
    "from utils.preprocessing import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "X, y, countries, y_mean, y_std = preprocess_data(data=data, epsilon=EPS)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = 0.9\n",
    "number_train = int(len(X) * percent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "# Add previous GDP as input\n",
    "x_values = np.hstack([x_values[1:], y_values[:-1][:, None], x_values[:-1]])\n",
    "y_values = y_values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X.values[:number_train, :]\n",
    "y_train = y.values[:number_train]\n",
    "x_valid = X.values[number_train:, :]\n",
    "y_valid = y.values[number_train:]\n",
    "country_train = countries.values[:number_train]\n",
    "country_valid = countries.values[number_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_norm(module, lip):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        with torch.no_grad():\n",
    "            # Compute the largest singular value (spectral norm) of the weight matrix\n",
    "            sigma = torch.linalg.norm(module.weight, ord=2)\n",
    "            # Scale the weight matrix to have spectral norm equal to 'lip'\n",
    "            if sigma > EPS:\n",
    "                scaling_factor = lip / sigma\n",
    "                module.weight.mul_(scaling_factor)\n",
    "\n",
    "def enforce_lipschitz(model, lip):\n",
    "    model.apply(lambda x: spectral_norm(x, lip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-5, lipschitz=None):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss = loss_fn(y_pred, y_train_t)\n",
    "        if t % 500 == 499:\n",
    "            print(t, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if lipschitz is not None:\n",
    "            enforce_lipschitz(model, lipschitz)\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss.item(), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothness_measure(sequence, real_sequence):\n",
    "    with torch.no_grad():\n",
    "        diff_diff = torch.diff(sequence.squeeze()) - torch.diff(real_sequence.squeeze())\n",
    "        return (torch.linalg.norm(diff_diff) / diff_diff.shape[0]).clone().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "losses = []\n",
    "\n",
    "parameter_space = np.linspace(1e-1, 1, 30)\n",
    "for l in parameter_space:\n",
    "    model, loss, y_pred = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-5, lipschitz=l)\n",
    "\n",
    "    smoothness = smoothness_measure(y_pred, y_valid_t)\n",
    "\n",
    "    print(f\"Lipschitz: {l}, Loss: {loss}, Smoothness: {smoothness}\")\n",
    "    losses.append({'lip': l, 'loss': loss, 'model': model, 'smoothness': smoothness})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with different y axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Lipschitz')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "\n",
    "ax1.plot([l['lip'] for l in losses], [l['loss'] for l in losses], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Smoothness', color=color)\n",
    "\n",
    "ax2.plot([l['lip'] for l in losses], [l['smoothness'] for l in losses], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_smoothness = np.argmin([l['smoothness'] for l in losses])\n",
    "smallest_loss = np.argmin([l['loss'] for l in losses])\n",
    "\n",
    "print(f\"Smallest smoothness: {losses[smallest_smoothness]}\")\n",
    "print(f\"Smallest loss: {losses[smallest_loss]}\")\n",
    "\n",
    "model = losses[smallest_loss]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = losses[0]['model']\n",
    "\n",
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country\n",
    "y_pred_country = pd.DataFrame({'date': X['date'][number_train:], 'country': country_valid, 'y_pred': y_pred, 'y_true': y_valid})\n",
    "y_pred_train_country = pd.DataFrame({'date': X['date'][:number_train], 'country': country_train, 'y_pred': y_pred_train, 'y_true': y_train})\n",
    "y_pred_train_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\"], value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    cutoff_date = predictions['date'].quantile(percent_train)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", style=\"Type\", markers=True, dashes=False\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({percent_train}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
