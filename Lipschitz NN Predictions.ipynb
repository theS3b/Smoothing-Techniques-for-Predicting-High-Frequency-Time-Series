{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.load_data import load_data\n",
    "from utils.preprocessing import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550, 102), (550,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "X, y, countries, y_mean, y_std = preprocess_data(data=data, epsilon=EPS)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>...</th>\n",
       "      <th>Artificial_intelligence_average</th>\n",
       "      <th>International_Financial_Reporting_Standards_average</th>\n",
       "      <th>Employment_average</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Korea</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-1.060998</td>\n",
       "      <td>2.871241</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>1.582391</td>\n",
       "      <td>-0.732737</td>\n",
       "      <td>-0.290201</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>-0.078562</td>\n",
       "      <td>0.186376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395035</td>\n",
       "      <td>-1.710910</td>\n",
       "      <td>1.689417</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-0.036149</td>\n",
       "      <td>3.231815</td>\n",
       "      <td>0.589877</td>\n",
       "      <td>1.653900</td>\n",
       "      <td>-0.682008</td>\n",
       "      <td>1.399695</td>\n",
       "      <td>0.082269</td>\n",
       "      <td>1.703260</td>\n",
       "      <td>0.763066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453614</td>\n",
       "      <td>-0.598496</td>\n",
       "      <td>1.689417</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>2.404079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-1.009755</td>\n",
       "      <td>2.751050</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>1.718909</td>\n",
       "      <td>-1.037115</td>\n",
       "      <td>-0.773029</td>\n",
       "      <td>1.073548</td>\n",
       "      <td>2.594171</td>\n",
       "      <td>2.276877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277877</td>\n",
       "      <td>0.745672</td>\n",
       "      <td>2.102636</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-0.446089</td>\n",
       "      <td>2.210188</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>0.516251</td>\n",
       "      <td>0.636960</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>0.875986</td>\n",
       "      <td>3.790689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336456</td>\n",
       "      <td>-1.710910</td>\n",
       "      <td>1.839678</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>2.421635</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>2.782184</td>\n",
       "      <td>-2.417180</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>1.426370</td>\n",
       "      <td>-1.290762</td>\n",
       "      <td>1.327271</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>2.530535</td>\n",
       "      <td>-3.273765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043561</td>\n",
       "      <td>-1.710910</td>\n",
       "      <td>0.900544</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Expense_average  Research_and_development_average  \\\n",
       "616  -1.771126        -1.060998                          2.871241   \n",
       "6646 -1.771126        -0.036149                          3.231815   \n",
       "6173 -1.771126        -1.009755                          2.751050   \n",
       "3645 -1.771126        -0.446089                          2.210188   \n",
       "5892 -1.771126         2.782184                         -2.417180   \n",
       "\n",
       "      Capital_expenditure_average  Business_average  Cost_average  \\\n",
       "616                     -1.696290          1.582391     -0.732737   \n",
       "6646                     0.589877          1.653900     -0.682008   \n",
       "6173                    -1.696290          1.718909     -1.037115   \n",
       "3645                    -1.696290          0.516251      0.636960   \n",
       "5892                    -1.696290          1.426370     -1.290762   \n",
       "\n",
       "      Tax_average  Financial_capital_average  Investment_average  \\\n",
       "616     -0.290201                  -0.604001           -0.078562   \n",
       "6646     1.399695                   0.082269            1.703260   \n",
       "6173    -0.773029                   1.073548            2.594171   \n",
       "3645     0.313333                  -0.604001            0.875986   \n",
       "5892     1.327271                  -0.604001            2.530535   \n",
       "\n",
       "      Gross_domestic_product_average  ...  Artificial_intelligence_average  \\\n",
       "616                         0.186376  ...                        -0.395035   \n",
       "6646                        0.763066  ...                        -0.453614   \n",
       "6173                        2.276877  ...                        -0.277877   \n",
       "3645                        3.790689  ...                        -0.336456   \n",
       "5892                       -3.273765  ...                        -0.043561   \n",
       "\n",
       "      International_Financial_Reporting_Standards_average  Employment_average  \\\n",
       "616                                           -1.710910              1.689417   \n",
       "6646                                          -0.598496              1.689417   \n",
       "6173                                           0.745672              2.102636   \n",
       "3645                                          -1.710910              1.839678   \n",
       "5892                                          -1.710910              0.900544   \n",
       "\n",
       "      country_Canada  country_Germany  country_Japan  country_Korea  \\\n",
       "616         2.404079        -0.415203      -0.365755      -0.412193   \n",
       "6646       -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "6173       -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "3645       -0.415203        -0.415203      -0.365755       2.421635   \n",
       "5892       -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "\n",
       "      country_Switzerland  country_United Kingdom  country_United States  \n",
       "616             -0.415203               -0.415203              -0.415203  \n",
       "6646            -0.415203               -0.415203               2.404079  \n",
       "6173            -0.415203                2.404079              -0.415203  \n",
       "3645            -0.415203               -0.415203              -0.415203  \n",
       "5892             2.404079               -0.415203              -0.415203  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616             Canada\n",
       "6646     United States\n",
       "6173    United Kingdom\n",
       "3645             Korea\n",
       "5892       Switzerland\n",
       "             ...      \n",
       "856             Canada\n",
       "6413    United Kingdom\n",
       "2588           Germany\n",
       "6132       Switzerland\n",
       "6886     United States\n",
       "Name: country, Length: 550, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = 0.9\n",
    "number_train = int(len(X) * percent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X.values[:number_train, :]\n",
    "y_train = y.values[:number_train]\n",
    "x_valid = X.values[number_train:, :]\n",
    "y_valid = y.values[number_train:]\n",
    "country_train = countries.values[:number_train]\n",
    "country_valid = countries.values[number_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.get_parameter of NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=102, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get weights of linear layer\n",
    "model.get_parameter.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_norm(module, lip):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        with torch.no_grad():\n",
    "            # Compute the largest singular value (spectral norm) of the weight matrix\n",
    "            sigma = torch.linalg.norm(module.weight, ord=2)\n",
    "            # Scale the weight matrix to have spectral norm equal to 'lip'\n",
    "            if sigma > EPS:\n",
    "                scaling_factor = lip / sigma\n",
    "                module.weight.mul_(scaling_factor)\n",
    "\n",
    "def enforce_lipschitz(model, lip):\n",
    "    model.apply(lambda x: spectral_norm(x, lip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-5, lipschitz=None):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss = loss_fn(y_pred, y_train_t)\n",
    "        if t % 100 == 99:\n",
    "            print(t, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lipschitz is not None:\n",
    "            enforce_lipschitz(model, lipschitz)\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model, loss.item(), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothness_measure(sequence, real_sequence):\n",
    "    with torch.no_grad():\n",
    "        diff_diff = torch.diff(sequence.squeeze()) - torch.diff(real_sequence.squeeze())\n",
    "        return (torch.linalg.norm(diff_diff) / diff_diff.shape[0]).clone().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebge\\AppData\\Local\\Temp\\ipykernel_19680\\4136608418.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
      "C:\\Users\\sebge\\AppData\\Local\\Temp\\ipykernel_19680\\4136608418.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef15885e910e40378b303f9496d3a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.04157034680247307\n",
      "199 0.024520911276340485\n",
      "299 0.01791682094335556\n",
      "399 0.014509533531963825\n",
      "499 0.01295813824981451\n",
      "599 0.012011749669909477\n",
      "699 0.011394566856324673\n",
      "799 0.010792579501867294\n",
      "899 0.010438784025609493\n",
      "999 0.010311717167496681\n",
      "Validation loss: 0.40269947052001953\n",
      "Lipschitz: 0.8, Loss: 0.40269947052001953, Smoothness: 0.10319431871175766\n"
     ]
    }
   ],
   "source": [
    "y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "parameter_space = np.logspace(np.log(1), np.log(10), 100, base=np.e)\n",
    "l = 8e-1\n",
    "\n",
    "model, loss, y_pred = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-5, lipschitz=l)\n",
    "\n",
    "smoothness = smoothness_measure(y_pred, y_valid_t)\n",
    "\n",
    "print(f\"Lipschitz: {l}, Loss: {loss}, Smoothness: {smoothness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebge\\AppData\\Local\\Temp\\ipykernel_19680\\3213738682.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
      "C:\\Users\\sebge\\AppData\\Local\\Temp\\ipykernel_19680\\3213738682.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>Canada</td>\n",
       "      <td>-1.094013</td>\n",
       "      <td>-1.110615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>United States</td>\n",
       "      <td>-0.574104</td>\n",
       "      <td>-0.539413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>-1.205533</td>\n",
       "      <td>-1.228650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>Korea</td>\n",
       "      <td>-1.867367</td>\n",
       "      <td>-1.837559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>-0.674437</td>\n",
       "      <td>-0.636078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>1.366397</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.582981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>1.366397</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.961822</td>\n",
       "      <td>0.938508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>1.366397</td>\n",
       "      <td>Japan</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>-0.146885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>1.366397</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0.124369</td>\n",
       "      <td>0.173998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>1.366397</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1.332856</td>\n",
       "      <td>1.365879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date         country    y_pred    y_true\n",
       "616  -1.771126          Canada -1.094013 -1.110615\n",
       "6646 -1.771126   United States -0.574104 -0.539413\n",
       "6173 -1.771126  United Kingdom -1.205533 -1.228650\n",
       "3645 -1.771126           Korea -1.867367 -1.837559\n",
       "5892 -1.771126     Switzerland -0.674437 -0.636078\n",
       "...        ...             ...       ...       ...\n",
       "6389  1.366397  United Kingdom  0.724668  0.582981\n",
       "832   1.366397          Canada  0.961822  0.938508\n",
       "3527  1.366397           Japan -0.014836 -0.146885\n",
       "3861  1.366397           Korea  0.124369  0.173998\n",
       "2564  1.366397         Germany  1.332856  1.365879\n",
       "\n",
       "[495 rows x 4 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Associate the result by country\n",
    "y_pred_country = pd.DataFrame({'date': X['date'][number_train:], 'country': country_valid, 'y_pred': y_pred, 'y_true': y_valid})\n",
    "y_pred_train_country = pd.DataFrame({'date': X['date'][:number_train], 'country': country_train, 'y_pred': y_pred_train, 'y_true': y_train})\n",
    "y_pred_train_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fe176de78d4290a03260cc2fe23a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Country:', options=('Canada', 'United States', 'United Kingdom', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\"], value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    cutoff_date = predictions['date'].quantile(percent_train)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", style=\"Type\", markers=True, dashes=False\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({percent_train}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
