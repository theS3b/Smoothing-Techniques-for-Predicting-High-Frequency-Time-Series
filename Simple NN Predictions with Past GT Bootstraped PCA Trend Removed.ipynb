{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing import Preprocessing\n",
    "from utils.results import compute_rsquared\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils.downward_trend_removal as dtr\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ALL_GT_DATA = False # If set to True, the model will be trained on all available data and predictions will be made for all available GT data\n",
    "\n",
    "TRAIN_PROPORTION = 0.9 if not TEST_ALL_GT_DATA else 1\n",
    "PAST_GDPS = [] if not TEST_ALL_GT_DATA else None # e.g. range(1, 3) or [1, 2]\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 4  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_gdps, all_gts = load_data()\n",
    "search_terms = [col for col in all_gts.columns if col.endswith('_average')]\n",
    "search_terms_trend_removal = search_terms + ['country', 'date']\n",
    "\n",
    "data[search_terms_trend_removal] = dtr.detrend_gts(data[search_terms_trend_removal], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_gts = all_gts.copy() # Monthly Google Trends\n",
    "processed_gts['date'] = pd.to_datetime(processed_gts['date'])\n",
    "processed_gts[search_terms] = np.log(processed_gts[search_terms] + 1)\n",
    "\n",
    "for nb_years in range(1, 3): # 3 will add 2 years difference\n",
    "    diff = (processed_gts[search_terms] - processed_gts.groupby(\"country\")[search_terms].diff(nb_years * 12)).add_suffix(f'_{nb_years}y_diff')\n",
    "    processed_gts = pd.concat([processed_gts, diff], axis=1)\n",
    "\n",
    "processed_gts.drop(columns=search_terms, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "processed_gts = processed_gts.dropna()\n",
    "data_merged = data.merge(processed_gts, left_on=[\"country\", \"date\"], right_on=[\"country\", \"date\"], how=\"left\")\n",
    "data_merged['date'] = pd.to_datetime(data_merged['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Data merged shape: {data_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dt = data_merged.copy()\n",
    "data_dt['date'] = pd.to_datetime(data_dt['date'])\n",
    "splitting_date = data_dt['date'].quantile(TRAIN_PROPORTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing(data=data_merged, epsilon=EPS, mode=MODE, past_GDP_lags=PAST_GDPS, diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION, shuffle=False, splitting_date=splitting_date)\n",
    "\n",
    "X_train[preprocessor.country_train == \"Switzerland\"].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Print all columns that contain Research_and_development\n",
    "search_term = \"Research_and_development\"\n",
    "search_cols = [col for col in X_train.columns if search_term in col]\n",
    "other_cols = []\n",
    "X_train[preprocessor.country_train == \"Switzerland\"][search_cols + other_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "pca = PCA(150)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_valid_pca = pca.transform(X_valid)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum()}\")\n",
    "plot.figure(figsize=(10, 6))\n",
    "plot.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Plot singular values\n",
    "plot.figure(figsize=(10, 6))\n",
    "plot.plot(pca.singular_values_)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = X_train.values\n",
    "# x_valid = X_valid.values\n",
    "x_train = X_train_pca\n",
    "x_valid = X_valid_pca\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "country_train = preprocessor.country_train\n",
    "country_valid = preprocessor.country_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "# Function to set random seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch for all GPUs (if multiple GPUs are used)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic optimizations\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=2000, learning_rate=1e-3, weight_decay=1e-3, verbose = True):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    valid_r_squared = []\n",
    "    \n",
    "    epoch_range = tqdm(range(num_epochs)) if verbose else range(num_epochs)\n",
    "    for t in epoch_range:\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "\n",
    "        valid_r_squared.append(r_squared)\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "\n",
    "    v_loss = loss_fn(y_pred, y_valid_t)\n",
    "    validation_loss.append(v_loss.item())\n",
    "    print(f\"Validation loss: {v_loss.item()}\")\n",
    "\n",
    "    t_loss = loss_fn(model(x_train_t), y_train_t)\n",
    "    training_loss.append(t_loss.item())\n",
    "    print(f\"Training loss: {t_loss.item()}\")\n",
    "\n",
    "    r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "    valid_r_squared.append(r_squared)\n",
    "    print(f\"Validation R^2: {r_squared}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss, valid_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss, validation_r_squared = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=300, learning_rate=1e-3, weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.plot(validation_r_squared, label=\"Validation R^2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bootrapping\n",
    "n_bootstrap = 250\n",
    "n = len(x_train)\n",
    "n_features = x_train.shape[1]\n",
    "\n",
    "n_countries = len(np.unique(country_train))\n",
    "\n",
    "bootstrap_size = n // n_countries # np.ceil(150 / n_countries).astype(int)\n",
    "\n",
    "bootstrap_models = []\n",
    "mse_bootstrap = np.zeros(n_bootstrap)\n",
    "rsquared_bootstrap = np.zeros(n_bootstrap)\n",
    "\n",
    "for i in tqdm(range(n_bootstrap)):\n",
    "    # Make a bootstrap sample of size bootstrap_size\n",
    "    set_seed(SEED + i)\n",
    "\n",
    "    indices_per_country = [np.where(country_train == c)[0] for c in np.unique(country_train)]\n",
    "    bootstrap_idx = np.concatenate([np.random.choice(indices, size=bootstrap_size, replace=True) for indices in indices_per_country])\n",
    "    x_train_bootstrap = x_train[bootstrap_idx]\n",
    "    y_train_bootstrap = y_train[bootstrap_idx]\n",
    "\n",
    "    model_bootstrap, _, _, _ = train_nn(x_train_bootstrap, y_train_bootstrap, x_valid, y_valid, num_epochs=50, learning_rate=1e-3, weight_decay=5e-2, verbose=False)\n",
    "    y_pred = model_bootstrap(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rsquared = compute_rsquared(y_valid, y_pred)\n",
    "\n",
    "    bootstrap_models.append(model_bootstrap)\n",
    "    mse_bootstrap[i] = mse\n",
    "    rsquared_bootstrap[i] = rsquared\n",
    "\n",
    "# Aggregate the predictions\n",
    "y_pred = np.zeros((x_valid.shape[0], n_bootstrap))\n",
    "for i in range(n_bootstrap):\n",
    "    y_pred[:, i] = bootstrap_models[i](torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "y_pred_mean = np.mean(y_pred, axis=1)\n",
    "y_pred_std = np.std(y_pred, axis=1)\n",
    "y_pred_median = np.median(y_pred, axis=1)\n",
    "\n",
    "# Get the model with the best R squared\n",
    "best_model_idx = np.argmax(rsquared_bootstrap)\n",
    "best_model = bootstrap_models[best_model_idx]\n",
    "best_rsquared = rsquared_bootstrap[best_model_idx]\n",
    "y_pred_best = best_model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(mse_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the r squared\n",
    "bootstrapped_r2 = compute_rsquared(y_valid, y_pred_mean)\n",
    "print(f\"Bootstrapped R^2: {bootstrapped_r2}\")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(rsquared_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"R squared\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions per country, per date\n",
    "def plot_by_country(selected_country):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(y_valid[country_valid == selected_country], label=\"True\")\n",
    "    plt.plot(y_pred_mean[country_valid == selected_country], label=\"Predicted\")\n",
    "    plt.plot(y_pred_median[country_valid == selected_country], label=\"Predicted (median)\")\n",
    "    plt.plot(y_pred_best[country_valid == selected_country], label=\"Predicted (best)\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 3 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 3 * y_pred_std[country_valid == selected_country], alpha=0.05, color=\"red\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 1.96 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 1.96 * y_pred_std[country_valid == selected_country], alpha=0.2)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"GDP\")\n",
    "    plt.title(f\"{selected_country}\")\n",
    "    plt.legend()\n",
    "\n",
    "interact(plot_by_country, selected_country=np.unique(country_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BASED ONLY ON THE FIRST MODEL !! NOT THE BOOTSTRAP MODELS\n",
    "\n",
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country and add 'Set' column\n",
    "y_pred_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_valid,\n",
    "    'country': country_valid,\n",
    "    'y_pred': y_pred,\n",
    "    'y_true': y_valid,\n",
    "    'Set': 'Validation'\n",
    "})\n",
    "\n",
    "y_pred_train_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train,\n",
    "    'country': country_train,\n",
    "    'y_pred': y_pred_train,\n",
    "    'y_true': y_train,\n",
    "    'Set': 'Training'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None, style=\"Set\", markers=True\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[(predictions_melted[\"country\"] == selected_country) & (predictions_melted[\"Set\"] == \"Validation\")]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
