{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.load_data import load_data\n",
    "from utils.preprocessing import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from postprocessing.arima import postprocess_arima\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550, 102), (550,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "X, y, countries, y_mean, y_std = preprocess_data(data=data, epsilon=EPS)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>...</th>\n",
       "      <th>Artificial_intelligence_average</th>\n",
       "      <th>International_Financial_Reporting_Standards_average</th>\n",
       "      <th>Employment_average</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Korea</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>2.782184</td>\n",
       "      <td>-2.417180</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>1.426370</td>\n",
       "      <td>-1.290762</td>\n",
       "      <td>1.327271</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>2.530535</td>\n",
       "      <td>-3.273765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043561</td>\n",
       "      <td>-1.710910</td>\n",
       "      <td>0.900544</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-0.446089</td>\n",
       "      <td>2.210188</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>0.516251</td>\n",
       "      <td>0.636960</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>0.875986</td>\n",
       "      <td>3.790689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336456</td>\n",
       "      <td>-1.710910</td>\n",
       "      <td>1.839678</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>2.421635</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-1.009755</td>\n",
       "      <td>2.751050</td>\n",
       "      <td>-1.696290</td>\n",
       "      <td>1.718909</td>\n",
       "      <td>-1.037115</td>\n",
       "      <td>-0.773029</td>\n",
       "      <td>1.073548</td>\n",
       "      <td>2.594171</td>\n",
       "      <td>2.276877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277877</td>\n",
       "      <td>0.745672</td>\n",
       "      <td>2.102636</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>-0.036149</td>\n",
       "      <td>3.231815</td>\n",
       "      <td>0.589877</td>\n",
       "      <td>1.653900</td>\n",
       "      <td>-0.682008</td>\n",
       "      <td>1.399695</td>\n",
       "      <td>0.082269</td>\n",
       "      <td>1.703260</td>\n",
       "      <td>0.763066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453614</td>\n",
       "      <td>-0.598496</td>\n",
       "      <td>1.689417</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>2.404079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-1.771126</td>\n",
       "      <td>1.398639</td>\n",
       "      <td>0.707796</td>\n",
       "      <td>0.793092</td>\n",
       "      <td>1.231345</td>\n",
       "      <td>-1.595140</td>\n",
       "      <td>1.822169</td>\n",
       "      <td>-0.604001</td>\n",
       "      <td>1.957806</td>\n",
       "      <td>0.618893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395035</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.862979</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>2.404079</td>\n",
       "      <td>-0.365755</td>\n",
       "      <td>-0.412193</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "      <td>-0.415203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Expense_average  Research_and_development_average  \\\n",
       "2    -1.771126         2.782184                         -2.417180   \n",
       "1227 -1.771126        -0.446089                          2.210188   \n",
       "492  -1.771126        -1.009755                          2.751050   \n",
       "1472 -1.771126        -0.036149                          3.231815   \n",
       "247  -1.771126         1.398639                          0.707796   \n",
       "\n",
       "      Capital_expenditure_average  Business_average  Cost_average  \\\n",
       "2                       -1.696290          1.426370     -1.290762   \n",
       "1227                    -1.696290          0.516251      0.636960   \n",
       "492                     -1.696290          1.718909     -1.037115   \n",
       "1472                     0.589877          1.653900     -0.682008   \n",
       "247                      0.793092          1.231345     -1.595140   \n",
       "\n",
       "      Tax_average  Financial_capital_average  Investment_average  \\\n",
       "2        1.327271                  -0.604001            2.530535   \n",
       "1227     0.313333                  -0.604001            0.875986   \n",
       "492     -0.773029                   1.073548            2.594171   \n",
       "1472     1.399695                   0.082269            1.703260   \n",
       "247      1.822169                  -0.604001            1.957806   \n",
       "\n",
       "      Gross_domestic_product_average  ...  Artificial_intelligence_average  \\\n",
       "2                          -3.273765  ...                        -0.043561   \n",
       "1227                        3.790689  ...                        -0.336456   \n",
       "492                         2.276877  ...                        -0.277877   \n",
       "1472                        0.763066  ...                        -0.453614   \n",
       "247                         0.618893  ...                        -0.395035   \n",
       "\n",
       "      International_Financial_Reporting_Standards_average  Employment_average  \\\n",
       "2                                             -1.710910              0.900544   \n",
       "1227                                          -1.710910              1.839678   \n",
       "492                                            0.745672              2.102636   \n",
       "1472                                          -0.598496              1.689417   \n",
       "247                                            0.652970              0.862979   \n",
       "\n",
       "      country_Canada  country_Germany  country_Japan  country_Korea  \\\n",
       "2          -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "1227       -0.415203        -0.415203      -0.365755       2.421635   \n",
       "492        -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "1472       -0.415203        -0.415203      -0.365755      -0.412193   \n",
       "247        -0.415203         2.404079      -0.365755      -0.412193   \n",
       "\n",
       "      country_Switzerland  country_United Kingdom  country_United States  \n",
       "2                2.404079               -0.415203              -0.415203  \n",
       "1227            -0.415203               -0.415203              -0.415203  \n",
       "492             -0.415203                2.404079              -0.415203  \n",
       "1472            -0.415203               -0.415203               2.404079  \n",
       "247             -0.415203               -0.415203              -0.415203  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2          Switzerland\n",
       "1227             Korea\n",
       "492     United Kingdom\n",
       "1472     United States\n",
       "247            Germany\n",
       "             ...      \n",
       "732     United Kingdom\n",
       "487            Germany\n",
       "242        Switzerland\n",
       "1222            Canada\n",
       "1712     United States\n",
       "Name: country, Length: 550, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = 0.85\n",
    "number_train = int(len(X) * percent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X.values[:number_train, :]\n",
    "y_train = y.values[:number_train]\n",
    "x_valid = X.values[number_train:, :]\n",
    "y_valid = y.values[number_train:]\n",
    "country_train = countries.values[:number_train]\n",
    "country_valid = countries.values[number_train:]\n",
    "\n",
    "# Add bias term\n",
    "# x_train = np.hstack([x_train, np.ones((len(x_train), 1))])\n",
    "# x_valid = np.hstack([x_valid, np.ones((len(x_valid), 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-5):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss = loss_fn(y_pred, y_train_t)\n",
    "        if t % 100 == 99:\n",
    "            print(t, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc332fa710f48aeb4755d888f0b6722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.004879059735685587\n",
      "199 0.0014902094844728708\n",
      "299 0.000643925741314888\n",
      "399 0.00031768871122039855\n",
      "499 0.0001701113214949146\n",
      "599 0.00010166172432946041\n",
      "699 6.786381709389389e-05\n",
      "799 4.8634381528245285e-05\n",
      "899 3.548289532773197e-05\n",
      "999 2.593684257590212e-05\n",
      "1099 1.9022547348868102e-05\n",
      "1199 1.3981289157527499e-05\n",
      "1299 1.0194282367592677e-05\n",
      "1399 7.351657586696092e-06\n",
      "1499 5.261676960799377e-06\n",
      "1599 3.7446257010742556e-06\n",
      "1699 2.6329369120503543e-06\n",
      "1799 1.8268976873514475e-06\n",
      "1899 1.2930614730066736e-06\n",
      "1999 9.57142674451461e-07\n",
      "2099 7.248416977745364e-07\n",
      "2199 6.179837441777636e-07\n",
      "2299 5.68006669254828e-07\n",
      "2399 5.44290344350884e-07\n",
      "2499 4.6197712322282314e-07\n",
      "2599 3.660356355794647e-07\n",
      "2699 1.833208216339699e-06\n",
      "2799 5.497514052876795e-07\n",
      "2899 2.3288937711640756e-07\n",
      "2999 1.8870603923915041e-07\n",
      "3099 6.999989636824466e-07\n",
      "3199 2.239506500245625e-07\n",
      "3299 3.672779030239326e-06\n",
      "3399 4.027601221423538e-07\n",
      "3499 2.678133341760258e-06\n",
      "3599 1.502757669413768e-07\n",
      "3699 4.4364520590534084e-07\n",
      "3799 2.360855432925746e-05\n",
      "3899 1.4943508119813487e-07\n",
      "3999 1.1233115060349519e-07\n",
      "4099 5.837528647134604e-07\n",
      "4199 2.0819619805934053e-07\n",
      "4299 6.166438311083766e-07\n",
      "4399 1.26771794839442e-07\n",
      "4499 8.414393960265443e-06\n",
      "4599 1.1134282829061704e-07\n",
      "4699 1.2203784535813611e-05\n",
      "4799 1.277548307143661e-07\n",
      "4899 4.610112227965146e-06\n",
      "4999 7.147002634155797e-07\n",
      "5099 2.069105721602682e-05\n",
      "5199 1.5242228073475417e-05\n",
      "5299 2.6449624783708714e-06\n",
      "5399 2.1025654461936938e-07\n",
      "5499 2.9728371941928344e-07\n",
      "5599 1.4081066410653875e-06\n",
      "5699 7.836513304937398e-08\n",
      "5799 1.57899773967074e-06\n",
      "5899 9.342124229760884e-08\n",
      "5999 1.7248856920559774e-06\n",
      "6099 2.182105163228698e-07\n",
      "6199 8.722836923880095e-07\n",
      "6299 1.039927823853759e-07\n",
      "6399 4.0181583926823805e-07\n",
      "6499 1.052664941880721e-07\n",
      "6599 6.312883726877772e-08\n",
      "6699 2.245646555820713e-06\n",
      "6799 7.477341057438025e-08\n",
      "6899 2.055369492381942e-07\n",
      "6999 1.4693560501655156e-07\n",
      "7099 7.713613285886822e-07\n",
      "7199 2.2849246761325048e-07\n",
      "7299 7.186771995293384e-07\n",
      "7399 1.061436819327355e-06\n",
      "7499 1.2988647313250112e-07\n",
      "7599 5.457737017877662e-08\n",
      "7699 7.33551278244704e-05\n",
      "7799 9.312554993812228e-07\n",
      "7899 6.140876251947702e-08\n",
      "7999 6.704468091811577e-07\n",
      "8099 4.4566334622686554e-07\n",
      "8199 5.794330354547128e-05\n",
      "8299 3.9337373891612515e-05\n",
      "8399 2.8001410100841895e-05\n",
      "8499 0.00010328993084840477\n",
      "8599 3.0859343951306073e-06\n",
      "8699 7.864553452918699e-08\n",
      "8799 3.273863967478974e-06\n",
      "8899 3.5095581552013755e-06\n",
      "8999 8.271106253232574e-07\n",
      "9099 3.070598904741928e-05\n",
      "9199 2.5773169909371063e-07\n",
      "9299 9.339808570985042e-08\n",
      "9399 0.00016500971105415374\n",
      "9499 8.70407106390303e-08\n",
      "9599 7.993602594069671e-06\n",
      "9699 3.4426452657498885e-06\n",
      "9799 1.0402251291452558e-06\n",
      "9899 7.737311591426987e-08\n",
      "9999 5.417711577138107e-07\n",
      "Validation loss: 0.32999926805496216\n"
     ]
    }
   ],
   "source": [
    "model = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=10000, learning_rate=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country\n",
    "y_pred_country = pd.DataFrame({'date': X['date'][number_train:], 'country': country_valid, 'y_pred': y_pred, 'y_true': y_valid})\n",
    "y_pred_train_country = pd.DataFrame({'date': X['date'][:number_train], 'country': country_train, 'y_pred': y_pred_train, 'y_true': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Validation MSE: 0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Apply arima on top of the predictions\n",
    "# Apply the post-processing function\n",
    "p = 3 # AR\n",
    "d = 1 # I \n",
    "q = 3 # MA\n",
    "adjusted_predictions = postprocess_arima(y_pred_train_country, y_pred_country, p, d, q)\n",
    "\n",
    "# # Evaluate adjusted predictions\n",
    "valid_adjusted = adjusted_predictions[adjusted_predictions['set'] == 'validation']\n",
    "train_adjusted = adjusted_predictions[adjusted_predictions['set'] == 'train']\n",
    "\n",
    "mse_valid_adjusted = mean_squared_error(valid_adjusted['y_true'], valid_adjusted['y_pred'])\n",
    "print(f\"Adjusted Validation MSE: {mse_valid_adjusted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca0646703d54c3eb0f6159a068b2d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Country:', options=('Canada', 'Japan', 'Switzerland', 'Korea', 'Un…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_country, y_pred_train_country])\n",
    "predictions_adjusted = pd.concat([train_adjusted, valid_adjusted])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\"], value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    cutoff_date = predictions['date'].quantile(percent_train)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", style=\"Type\", markers=True, dashes=False\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({percent_train}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
