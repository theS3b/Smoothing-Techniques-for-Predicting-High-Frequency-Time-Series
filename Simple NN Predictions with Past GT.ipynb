{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing import Preprocessing\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ALL_GT_DATA = False # If set to True, the model will be trained on all available data and predictions will be made for all available GT data\n",
    "\n",
    "TRAIN_PROPORTION = 0.94 if not TEST_ALL_GT_DATA else 1\n",
    "PAST_GDPS = [] if not TEST_ALL_GT_DATA else None # e.g. range(1, 3) or [1, 2]\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 4  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_gdps, all_gts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [col for col in all_gts.columns if col.endswith('_average')]\n",
    "\n",
    "processed_gts = all_gts.copy()\n",
    "processed_gts['date'] = pd.to_datetime(processed_gts['date'])\n",
    "processed_gts[search_terms] = np.log(processed_gts[search_terms] + 1)\n",
    "\n",
    "for nb_quarters in range(1, 4 * 2 + 1):\n",
    "    diff = (processed_gts[search_terms] - processed_gts.groupby(\"country\")[search_terms].diff(3 * nb_quarters)).add_prefix(f'q{nb_quarters}-')\n",
    "    processed_gts = pd.concat([processed_gts, diff], axis=1)\n",
    "\n",
    "processed_gts.drop(columns=search_terms, inplace=True)\n",
    "\n",
    "def get_gt_diff_logs(all_gts):\n",
    "    processed_gts = all_gts.copy()\n",
    "\n",
    "    search_terms = [col for col in all_gts.columns if col.endswith('_average')]\n",
    "    \n",
    "    processed_gts['date'] = pd.to_datetime(processed_gts['date'])\n",
    "    processed_gts[search_terms] = np.log(processed_gts[search_terms] + 1)\n",
    "\n",
    "    for nb_quarters in range(1, 4 * 2 + 1):\n",
    "        diff = (processed_gts[search_terms] - processed_gts.groupby(\"country\")[search_terms].diff(3 * nb_quarters)).add_prefix(f'q{nb_quarters}-')\n",
    "        processed_gts = pd.concat([processed_gts, diff], axis=1)\n",
    "\n",
    "    processed_gts.drop(columns=search_terms, inplace=True)\n",
    "\n",
    "    return processed_gts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "processed_gts = processed_gts.dropna()\n",
    "data_merged = data.merge(processed_gts, left_on=[\"country\", \"date\"], right_on=[\"country\", \"date\"], how=\"left\")\n",
    "data_merged['date'] = pd.to_datetime(data_merged['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Data merged shape: {data_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_date = data['date'].quantile(TRAIN_PROPORTION)\n",
    "splitting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing(data=data_merged, epsilon=EPS, mode=MODE, past_GDP_lags=PAST_GDPS, diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION)\n",
    "\n",
    "X_train[preprocessor.country_train == \"Switzerland\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.values\n",
    "x_valid = X_valid.values\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "country_train = preprocessor.country_train\n",
    "country_valid = preprocessor.country_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-3):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=25, learning_rate=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mape_score(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + EPS)))\n",
    "\n",
    "preds_valid= model(torch.tensor(x_valid, dtype=torch.float32).to(device)).detach().cpu().numpy().squeeze()\n",
    "\n",
    "scores = []\n",
    "mape_scores = []\n",
    "for i in range(2, y_valid.shape[0]):\n",
    "    r2 = r2_score(y_valid[:i].squeeze(), preds_valid[:i])\n",
    "    scores.append(r2)\n",
    "    mape_scores.append(mape_score(y_valid[:i].squeeze(), preds_valid[:i]))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(scores)\n",
    "plt.subplot(212)\n",
    "plt.plot(mape_scores)\n",
    "plt.grid()\n",
    "plt.ylim(0, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_valid, label=\"Predictions\")\n",
    "plt.plot(y_valid, label=\"True values\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y_valid.squeeze(), preds_valid.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value**2, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(torch.tensor(x_train, dtype=torch.float32).to(device)).detach().cpu().numpy()\n",
    "\n",
    "scores = []\n",
    "for i in range(8, y_train.shape[0]):\n",
    "    r2 = r2_score(y_train[:i], preds[:i])\n",
    "    scores.append(r2)\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country\n",
    "y_pred_country = pd.DataFrame({'date': preprocessor.dates_valid, 'country': country_valid, 'y_pred': y_pred, 'y_true': y_valid})\n",
    "y_pred_train_country = pd.DataFrame({'date': preprocessor.dates_train, 'country': country_train, 'y_pred': y_pred_train, 'y_true': y_train})\n",
    "y_pred_train_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\"], value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    cutoff_date = predictions['date'].quantile(TRAIN_PROPORTION)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", style=\"Type\", markers=True, dashes=False, errorbar=None\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({TRAIN_PROPORTION}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions[predictions[\"country\"] == selected_country]\n",
    "    filtered_data = filtered_data.sort_values(by='date')\n",
    "    cutoff_date = splitting_date\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot the true values\n",
    "    plt.plot(filtered_data['date'], filtered_data['y_true'], label='True Values', color='blue')\n",
    "    \n",
    "    # Plot the predicted mean\n",
    "    plt.plot(filtered_data['date'], filtered_data['y_pred'], label='Predicted Mean', color='orange')\n",
    "    \n",
    "    # Add the prediction interval\n",
    "    # plt.fill_between(\n",
    "    #     filtered_data['date'],\n",
    "    #     filtered_data['y_pred_lower'],\n",
    "    #     filtered_data['y_pred_upper'],\n",
    "    #     color='orange', alpha=0.2, label='95% Prediction Interval'\n",
    "    # )\n",
    "    \n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({TRAIN_PROPORTION}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
