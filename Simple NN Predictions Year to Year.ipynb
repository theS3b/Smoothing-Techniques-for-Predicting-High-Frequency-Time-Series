{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing import Preprocessing\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ALL_GT_DATA = False # If set to True, the model will be trained on all available data and predictions will be made for all available GT data\n",
    "\n",
    "TRAIN_PROPORTION = 0.90 if not TEST_ALL_GT_DATA else 1\n",
    "PAST_GDPS = [] if not TEST_ALL_GT_DATA else None # e.g. range(1, 3) or [1, 2]\n",
    "NB_PAST_GT = 1 if not TEST_ALL_GT_DATA else None # The number of past year-to-year Google Trends data to consider\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 4  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (550, 97)\n",
      "X_train shape : (469, 101)\n",
      "X_valid shape : (53, 101)\n",
      "y_train shape : (469,)\n",
      "y_valid shape : (53,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>...</th>\n",
       "      <th>Semiconductor_average</th>\n",
       "      <th>Artificial_intelligence_average</th>\n",
       "      <th>International_Financial_Reporting_Standards_average</th>\n",
       "      <th>Employment_average</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Korea</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>184</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>275</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>365</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    date  Expense_average  Research_and_development_average  \\\n",
       "0      0             53.0                              32.0   \n",
       "11    92             54.0                               0.0   \n",
       "14   184             43.0                               0.0   \n",
       "22   275             43.0                              26.0   \n",
       "28   365             45.0                              16.0   \n",
       "\n",
       "    Capital_expenditure_average  Business_average  Cost_average  Tax_average  \\\n",
       "0                           0.0              83.0          29.0         64.0   \n",
       "11                          0.0              73.0          30.0         33.0   \n",
       "14                          0.0              76.0          28.0         29.0   \n",
       "22                          0.0              68.0          24.0         30.8   \n",
       "28                          0.0              77.0          29.0         54.0   \n",
       "\n",
       "    Financial_capital_average  Investment_average  \\\n",
       "0                         0.0                86.0   \n",
       "11                        0.0                82.0   \n",
       "14                        0.0                88.0   \n",
       "22                        0.0                66.0   \n",
       "28                        0.0                75.0   \n",
       "\n",
       "    Gross_domestic_product_average  ...  Semiconductor_average  \\\n",
       "0                             32.0  ...                   51.0   \n",
       "11                            31.0  ...                   74.0   \n",
       "14                            31.0  ...                   58.0   \n",
       "22                            30.0  ...                   45.0   \n",
       "28                            31.0  ...                   40.0   \n",
       "\n",
       "    Artificial_intelligence_average  \\\n",
       "0                               8.0   \n",
       "11                              7.0   \n",
       "14                              8.0   \n",
       "22                              8.0   \n",
       "28                              9.0   \n",
       "\n",
       "    International_Financial_Reporting_Standards_average  Employment_average  \\\n",
       "0                                                48.2                  54.0   \n",
       "11                                               11.0                  63.0   \n",
       "14                                               57.8                  63.0   \n",
       "22                                               66.0                  40.0   \n",
       "28                                               60.8                  55.0   \n",
       "\n",
       "    country_Germany  country_Japan  country_Korea  country_Switzerland  \\\n",
       "0             False          False          False                 True   \n",
       "11            False          False          False                 True   \n",
       "14            False          False          False                 True   \n",
       "22            False          False          False                 True   \n",
       "28            False          False          False                 True   \n",
       "\n",
       "    country_United Kingdom  country_United States  \n",
       "0                    False                  False  \n",
       "11                   False                  False  \n",
       "14                   False                  False  \n",
       "22                   False                  False  \n",
       "28                   False                  False  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, all_gdps, all_gts = load_data()\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "preprocessor = Preprocessing(data=data, epsilon=EPS, mode=MODE, past_GDP_lags=PAST_GDPS, diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts, nb_past_GT=NB_PAST_GT)\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION)\n",
    "\n",
    "X_train[preprocessor.country_train == \"Switzerland\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>...</th>\n",
       "      <th>Agile_software_development_average</th>\n",
       "      <th>Subsidy_average</th>\n",
       "      <th>Sustainability_average</th>\n",
       "      <th>Open_innovation_average</th>\n",
       "      <th>Industrial_park_average</th>\n",
       "      <th>Semiconductor_average</th>\n",
       "      <th>Artificial_intelligence_average</th>\n",
       "      <th>International_Financial_Reporting_Standards_average</th>\n",
       "      <th>Employment_average</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-02-01</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-01</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-05-01</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  Expense_average  Research_and_development_average  \\\n",
       "0     2004-01-01         0.000000                          0.000000   \n",
       "1     2004-02-01         0.008248                          0.000000   \n",
       "2     2004-03-01         0.008250                          0.000000   \n",
       "3     2004-04-01         0.000000                          0.000000   \n",
       "4     2004-05-01         0.008245                          0.000000   \n",
       "...          ...              ...                               ...   \n",
       "1710  2024-01-01         0.008249                          0.008246   \n",
       "1711  2024-02-01         0.008250                          0.008247   \n",
       "1712  2024-03-01         0.008250                          0.008246   \n",
       "1713  2024-04-01         0.008250                          0.008247   \n",
       "1714  2024-05-01         0.008247                          0.008246   \n",
       "\n",
       "      Capital_expenditure_average  Business_average  Cost_average  \\\n",
       "0                        0.000000          0.008250      0.008242   \n",
       "1                        0.000000          0.008250      0.008243   \n",
       "2                        0.000000          0.008250      0.008242   \n",
       "3                        0.000000          0.008250      0.008242   \n",
       "4                        0.000000          0.008249      0.008242   \n",
       "...                           ...               ...           ...   \n",
       "1710                     0.008248          0.008249      0.008250   \n",
       "1711                     0.008250          0.008249      0.008249   \n",
       "1712                     0.008249          0.008249      0.008250   \n",
       "1713                     0.008250          0.008249      0.008250   \n",
       "1714                     0.008249          0.008248      0.008250   \n",
       "\n",
       "      Tax_average  Financial_capital_average  Investment_average  \\\n",
       "0        0.008245                   0.000000            0.008249   \n",
       "1        0.008248                   0.000000            0.008249   \n",
       "2        0.008248                   0.000000            0.008250   \n",
       "3        0.008245                   0.000000            0.008249   \n",
       "4        0.008244                   0.000000            0.008249   \n",
       "...           ...                        ...                 ...   \n",
       "1710     0.008249                   0.008205            0.008249   \n",
       "1711     0.008250                   0.008213            0.008249   \n",
       "1712     0.008249                   0.008213            0.008249   \n",
       "1713     0.008249                   0.008225            0.008249   \n",
       "1714     0.008246                   0.008213            0.008248   \n",
       "\n",
       "      Gross_domestic_product_average  ...  Agile_software_development_average  \\\n",
       "0                           0.008244  ...                            0.000000   \n",
       "1                           0.008244  ...                            0.000000   \n",
       "2                           0.000000  ...                            0.000000   \n",
       "3                           0.008246  ...                            0.000000   \n",
       "4                           0.008244  ...                            0.000000   \n",
       "...                              ...  ...                                 ...   \n",
       "1710                        0.008248  ...                            0.008249   \n",
       "1711                        0.008250  ...                            0.008249   \n",
       "1712                        0.008249  ...                            0.008249   \n",
       "1713                        0.008250  ...                            0.008249   \n",
       "1714                        0.008248  ...                            0.008248   \n",
       "\n",
       "      Subsidy_average  Sustainability_average  Open_innovation_average  \\\n",
       "0            0.008226                0.008246                 0.000000   \n",
       "1            0.008227                0.008245                 0.000000   \n",
       "2            0.000000                0.008245                 0.000000   \n",
       "3            0.000000                0.008246                 0.000000   \n",
       "4            0.000000                0.008245                 0.000000   \n",
       "...               ...                     ...                      ...   \n",
       "1710         0.008250                0.008249                 0.008240   \n",
       "1711         0.008250                0.008250                 0.008242   \n",
       "1712         0.008249                0.008249                 0.008245   \n",
       "1713         0.008249                0.008250                 0.008244   \n",
       "1714         0.008249                0.008249                 0.008240   \n",
       "\n",
       "      Industrial_park_average  Semiconductor_average  \\\n",
       "0                    0.000000               0.008248   \n",
       "1                    0.000000               0.008248   \n",
       "2                    0.000000               0.008250   \n",
       "3                    0.000000               0.008249   \n",
       "4                    0.000000               0.008248   \n",
       "...                       ...                    ...   \n",
       "1710                 0.008247               0.008240   \n",
       "1711                 0.008247               0.008242   \n",
       "1712                 0.008247               0.008242   \n",
       "1713                 0.008248               0.008242   \n",
       "1714                 0.008247               0.008240   \n",
       "\n",
       "      Artificial_intelligence_average  \\\n",
       "0                            0.008233   \n",
       "1                            0.008229   \n",
       "2                            0.008233   \n",
       "3                            0.008230   \n",
       "4                            0.008229   \n",
       "...                               ...   \n",
       "1710                         0.008249   \n",
       "1711                         0.008250   \n",
       "1712                         0.008250   \n",
       "1713                         0.008250   \n",
       "1714                         0.008250   \n",
       "\n",
       "      International_Financial_Reporting_Standards_average  Employment_average  \\\n",
       "0                                              0.008250              0.008248   \n",
       "1                                              0.008249              0.008248   \n",
       "2                                              0.000000              0.008248   \n",
       "3                                              0.008250              0.008248   \n",
       "4                                              0.000000              0.008247   \n",
       "...                                                 ...                   ...   \n",
       "1710                                           0.008241              0.008248   \n",
       "1711                                           0.008242              0.008245   \n",
       "1712                                           0.008241              0.008248   \n",
       "1713                                           0.008241              0.008249   \n",
       "1714                                           0.008240              0.008248   \n",
       "\n",
       "            country  \n",
       "0       Switzerland  \n",
       "1       Switzerland  \n",
       "2       Switzerland  \n",
       "3       Switzerland  \n",
       "4       Switzerland  \n",
       "...             ...  \n",
       "1710  United States  \n",
       "1711  United States  \n",
       "1712  United States  \n",
       "1713  United States  \n",
       "1714  United States  \n",
       "\n",
       "[1715 rows x 96 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal: Add the Year-over-Year Log-Difference of Search Volume Indices to the features\n",
    "\n",
    "# 1. Get the Year-over-Year Log-Difference of Search Volume Indices\n",
    "all_gts\n",
    "search_terms = [col for col in all_gts.columns if col.endswith('_average')]\n",
    "# Apply log\n",
    "all_gts.groupby(\"country\").apply()= np.log(all_gts.loc[all_gts[\"country\"] == country, search_terms] + 1)\n",
    "\n",
    "# 2. Add the previous year's difference to the features\n",
    "for term in search_terms:\n",
    "    all_gts.loc[all_gts[\"country\"] == country, f\"{term}_diff\"] = all_gts.loc[all_gts[\"country\"] == country, term].diff(3)\n",
    "\n",
    "all_gts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.values\n",
    "x_valid = X_valid.values\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "country_train = preprocessor.country_train\n",
    "country_valid = preprocessor.country_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.LayerNorm(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.LayerNorm(20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-4):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, training_loss, validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m, in \u001b[0;36mtrain_nn\u001b[0;34m(x_train, y_train, x_valid, y_valid, num_epochs, learning_rate, weight_decay)\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 26\u001b[0m x_train_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m y_train_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m x_valid_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_valid, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "model, training_loss, validation_loss = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=100, learning_rate=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country\n",
    "y_pred_country = pd.DataFrame({'date': X_valid['date'], 'country': country_valid, 'y_pred': y_pred, 'y_true': y_valid})\n",
    "y_pred_train_country = pd.DataFrame({'date': X_train['date'], 'country': country_train, 'y_pred': y_pred_train, 'y_true': y_train})\n",
    "y_pred_train_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\"], value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    cutoff_date = predictions['date'].quantile(TRAIN_PROPORTION)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", style=\"Type\", markers=True, dashes=False\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.axvline(x=cutoff_date, color='red', linestyle='--', label=f'Validation Start ({TRAIN_PROPORTION}%)')\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
