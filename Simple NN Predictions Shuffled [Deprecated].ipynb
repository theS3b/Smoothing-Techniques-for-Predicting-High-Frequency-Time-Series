{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing import Preprocessing\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ALL_GT_DATA = False # If set to True, the model will be trained on all available data and predictions will be made for all available GT data\n",
    "\n",
    "TRAIN_PROPORTION = 0.75 if not TEST_ALL_GT_DATA else 1\n",
    "PAST_GDPS = [] if not TEST_ALL_GT_DATA else None # e.g. range(1, 3) or [1, 2]\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 3  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (550, 97)\n",
      "X_train shape : (396, 104)\n",
      "X_valid shape : (133, 104)\n",
      "y_train shape : (396,)\n",
      "y_valid shape : (133,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expense_average</th>\n",
       "      <th>Research_and_development_average</th>\n",
       "      <th>Capital_expenditure_average</th>\n",
       "      <th>Business_average</th>\n",
       "      <th>Cost_average</th>\n",
       "      <th>Tax_average</th>\n",
       "      <th>Financial_capital_average</th>\n",
       "      <th>Investment_average</th>\n",
       "      <th>Gross_domestic_product_average</th>\n",
       "      <th>Credit_average</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Korea</th>\n",
       "      <th>country_Switzerland</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444242</td>\n",
       "      <td>-0.379066</td>\n",
       "      <td>-1.677117</td>\n",
       "      <td>0.836279</td>\n",
       "      <td>-1.422236</td>\n",
       "      <td>-0.841086</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>1.434865</td>\n",
       "      <td>-0.098191</td>\n",
       "      <td>0.219548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>-0.353107</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>2.386931</td>\n",
       "      <td>-0.41372</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.551608</td>\n",
       "      <td>-0.566002</td>\n",
       "      <td>-1.677117</td>\n",
       "      <td>1.205944</td>\n",
       "      <td>-1.173707</td>\n",
       "      <td>1.532267</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>2.008811</td>\n",
       "      <td>-0.970021</td>\n",
       "      <td>0.803951</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>-0.353107</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>2.386931</td>\n",
       "      <td>-0.41372</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.605292</td>\n",
       "      <td>-2.559992</td>\n",
       "      <td>-1.677117</td>\n",
       "      <td>0.869885</td>\n",
       "      <td>-1.111574</td>\n",
       "      <td>-0.644476</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>1.753724</td>\n",
       "      <td>-1.057204</td>\n",
       "      <td>1.073675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>-0.353107</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>2.386931</td>\n",
       "      <td>-0.41372</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014776</td>\n",
       "      <td>-2.559992</td>\n",
       "      <td>-1.677117</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>-1.235839</td>\n",
       "      <td>-0.925347</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>2.136355</td>\n",
       "      <td>-1.057204</td>\n",
       "      <td>0.714043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>-0.353107</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>2.386931</td>\n",
       "      <td>-0.41372</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.014776</td>\n",
       "      <td>-0.939875</td>\n",
       "      <td>-1.677117</td>\n",
       "      <td>0.701855</td>\n",
       "      <td>-1.484369</td>\n",
       "      <td>-0.798955</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>0.733376</td>\n",
       "      <td>-1.144387</td>\n",
       "      <td>0.399365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>-0.353107</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>2.386931</td>\n",
       "      <td>-0.41372</td>\n",
       "      <td>-0.41789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Expense_average  Research_and_development_average  \\\n",
       "1          0.444242                         -0.379066   \n",
       "6          0.551608                         -0.566002   \n",
       "17         0.605292                         -2.559992   \n",
       "20         0.014776                         -2.559992   \n",
       "28         0.014776                         -0.939875   \n",
       "\n",
       "    Capital_expenditure_average  Business_average  Cost_average  Tax_average  \\\n",
       "1                     -1.677117          0.836279     -1.422236    -0.841086   \n",
       "6                     -1.677117          1.205944     -1.173707     1.532267   \n",
       "17                    -1.677117          0.869885     -1.111574    -0.644476   \n",
       "20                    -1.677117          0.970703     -1.235839    -0.925347   \n",
       "28                    -1.677117          0.701855     -1.484369    -0.798955   \n",
       "\n",
       "    Financial_capital_average  Investment_average  \\\n",
       "1                   -0.614734            1.434865   \n",
       "6                   -0.614734            2.008811   \n",
       "17                  -0.614734            1.753724   \n",
       "20                  -0.614734            2.136355   \n",
       "28                  -0.614734            0.733376   \n",
       "\n",
       "    Gross_domestic_product_average  Credit_average  ...  country_Germany  \\\n",
       "1                        -0.098191        0.219548  ...         -0.41789   \n",
       "6                        -0.970021        0.803951  ...         -0.41789   \n",
       "17                       -1.057204        1.073675  ...         -0.41789   \n",
       "20                       -1.057204        0.714043  ...         -0.41789   \n",
       "28                       -1.144387        0.399365  ...         -0.41789   \n",
       "\n",
       "    country_Japan  country_Korea  country_Switzerland  country_United Kingdom  \\\n",
       "1       -0.353107       -0.41789             2.386931                -0.41372   \n",
       "6       -0.353107       -0.41789             2.386931                -0.41372   \n",
       "17      -0.353107       -0.41789             2.386931                -0.41372   \n",
       "20      -0.353107       -0.41789             2.386931                -0.41372   \n",
       "28      -0.353107       -0.41789             2.386931                -0.41372   \n",
       "\n",
       "    country_United States  month_3  month_6  month_9  month_12  \n",
       "1                -0.41789      0.0      0.0      0.0       1.0  \n",
       "6                -0.41789      1.0      0.0      0.0       0.0  \n",
       "17               -0.41789      0.0      1.0      0.0       0.0  \n",
       "20               -0.41789      0.0      0.0      1.0       0.0  \n",
       "28               -0.41789      0.0      0.0      0.0       1.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, all_gdps, all_gts = load_data()\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "\n",
    "preprocessor = Preprocessing(data=data, epsilon=EPS, mode=MODE, past_GDP_lags=PAST_GDPS, diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION)\n",
    "\n",
    "X_train[preprocessor.country_train == \"Switzerland\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.values\n",
    "x_valid = X_valid.values\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "country_train = preprocessor.country_train\n",
    "country_valid = preprocessor.country_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m y_full[split_idx:]\n\u001b[0;32m     19\u001b[0m country_valid \u001b[38;5;241m=\u001b[39m country_full[split_idx:]\n\u001b[1;32m---> 20\u001b[0m dates_shuffled \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[shuffle_idx]\n\u001b[0;32m     22\u001b[0m dates_train \u001b[38;5;241m=\u001b[39m dates_shuffled[:split_idx]\n\u001b[0;32m     23\u001b[0m dates_valid \u001b[38;5;241m=\u001b[39m dates_shuffled[split_idx:]\n",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\sebge\\miniconda3\\envs\\epfl-master\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "x_full = np.concatenate([x_train, x_valid], axis=0)\n",
    "y_full = np.concatenate([y_train, y_valid], axis=0)\n",
    "country_full = np.concatenate([country_train, country_valid], axis=0)\n",
    "\n",
    "# Shuffle data\n",
    "np.random.seed(SEED)\n",
    "shuffle_idx = np.random.permutation(x_full.shape[0]) # np.linspace(0, x_full.shape[0]-1, x_full.shape[0], dtype=int)\n",
    "x_full = x_full[shuffle_idx]\n",
    "y_full = y_full[shuffle_idx]\n",
    "country_full = country_full[shuffle_idx]\n",
    "\n",
    "# Split data\n",
    "split_idx = int(x_full.shape[0] * TRAIN_PROPORTION)\n",
    "x_train = x_full[:split_idx]\n",
    "y_train = y_full[:split_idx]\n",
    "country_train = country_full[:split_idx]\n",
    "x_valid = x_full[split_idx:]\n",
    "y_valid = y_full[split_idx:]\n",
    "country_valid = country_full[split_idx:]\n",
    "dates_shuffled = pd.concat([X_train, X_valid], axis=0)['date'].values[shuffle_idx]\n",
    "\n",
    "dates_train = dates_shuffled[:split_idx]\n",
    "dates_valid = dates_shuffled[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.LayerNorm(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.LayerNorm(20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=1000, learning_rate=1e-3, weight_decay=1e-4):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for t in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "    loss = loss_fn(y_pred, y_valid_t)\n",
    "    print(f\"Validation loss: {loss.item()}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss = train_nn(x_train, y_train, x_valid, y_valid, num_epochs=100, learning_rate=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country and add 'Set' column\n",
    "y_pred_country = pd.DataFrame({\n",
    "    'date': dates_valid,\n",
    "    'country': country_valid,\n",
    "    'y_pred': y_pred,\n",
    "    'y_true': y_valid,\n",
    "    'Set': 'Validation'\n",
    "})\n",
    "\n",
    "y_pred_train_country = pd.DataFrame({\n",
    "    'date': dates_train,\n",
    "    'country': country_train,\n",
    "    'y_pred': y_pred_train,\n",
    "    'y_true': y_train,\n",
    "    'Set': 'Training'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None, style=\"Set\"\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[(predictions_melted[\"country\"] == selected_country) & (predictions_melted[\"Set\"] == \"Validation\")]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
