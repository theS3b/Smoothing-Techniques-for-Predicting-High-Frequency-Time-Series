{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import load_data, load_gt_data\n",
    "from utils.preprocessing_v2 import Preprocessing, get_gt_diff_logs\n",
    "from utils.results import compute_rsquared\n",
    "from models.MLP import MLP\n",
    "from models.LinearModels import OLS, RidgeRegression\n",
    "from models.KalmanFilterMLP import KalmanFilterMLP\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TRENDS_FOLDER = 'data/google_trends/'\n",
    "GDP_FOLDER = 'data/gdp/'\n",
    "DATA_PREFIX = 'trends_data_by_topic_'\n",
    "\n",
    "EPS = 1e-15\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROPORTION = 0.9\n",
    "MODE = \"pct\" # None | \"pct\" | \"diff\"\n",
    "PERIOD = 4  # Year to year prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_gdps, all_gts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gdps['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing(epsilon=EPS, gdp_diff_period=PERIOD, all_GDPs=all_gdps, all_GTs=all_gts)\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, _ = preprocessor.preprocess_data(train_pct=TRAIN_PROPORTION, \n",
    "                                                                  mode=MODE, \n",
    "                                                                  gt_trend_removal=False, \n",
    "                                                                  keep_pca_components=180, \n",
    "                                                                  noisy_data_stds=[0.001, 0.005, 0.01], \n",
    "                                                                  add_encoded_month=False, \n",
    "                                                                  gt_data_transformations=[get_gt_diff_logs], other_params={'plot_pca': True})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gts['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "# Function to set random seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (if available)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch for all GPUs (if multiple GPUs are used)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic optimizations\n",
    "    \n",
    "def train_nn(x_train, y_train, x_valid, y_valid, num_epochs=2000, learning_rate=1e-3, weight_decay=1e-3, verbose = True):\n",
    "    num_features = x_train.shape[1]\n",
    "    model = NeuralNetwork(num_features=num_features).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    x_train_t = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "    x_valid_t = torch.tensor(x_valid, dtype=torch.float32).to(device)\n",
    "    y_valid_t = torch.tensor(y_valid, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    valid_r_squared = []\n",
    "    \n",
    "    epoch_range = tqdm(range(num_epochs)) if verbose else range(num_epochs)\n",
    "    for t in epoch_range:\n",
    "        model.train()\n",
    "        y_pred = model(x_train_t)\n",
    "        loss_train = loss_fn(y_pred, y_train_t)\n",
    "\n",
    "        model.eval()\n",
    "        loss_valid = loss_fn(model(x_valid_t), y_valid_t)\n",
    "        model.train()\n",
    "\n",
    "        r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "\n",
    "        valid_r_squared.append(r_squared)\n",
    "        training_loss.append(loss_train.item())\n",
    "        validation_loss.append(loss_valid.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    y_pred = model(x_valid_t)\n",
    "\n",
    "    v_loss = loss_fn(y_pred, y_valid_t)\n",
    "    validation_loss.append(v_loss.item())\n",
    "    print(f\"Validation loss: {v_loss.item()}\")\n",
    "\n",
    "    t_loss = loss_fn(model(x_train_t), y_train_t)\n",
    "    training_loss.append(t_loss.item())\n",
    "    print(f\"Training loss: {t_loss.item()}\")\n",
    "\n",
    "    r_squared = compute_rsquared(y_valid, model(torch.tensor(x_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten())\n",
    "    valid_r_squared.append(r_squared)\n",
    "    print(f\"Validation R^2: {r_squared}\")\n",
    "    \n",
    "    return model, training_loss, validation_loss, valid_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_loss, validation_loss, validation_r_squared = train_nn(X_train, y_train, X_valid, y_valid, num_epochs=1000, learning_rate=5e-4, weight_decay=7e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(training_loss, label=\"Training loss\")\n",
    "plt.plot(validation_loss, label=\"Validation loss\")\n",
    "plt.plot(validation_r_squared, label=\"Validation R^2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "#plt.xlim(0, 50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bootrapping\n",
    "n_bootstrap = 100\n",
    "n = len(X_train)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "n_countries = len(np.unique(preprocessor.country_train))\n",
    "\n",
    "bootstrap_size =  np.ceil(200 / n_countries).astype(int) # n // n_countries #\n",
    "\n",
    "bootstrap_models = []\n",
    "mse_bootstrap = np.zeros(n_bootstrap)\n",
    "rsquared_bootstrap = np.zeros(n_bootstrap)\n",
    "\n",
    "for i in tqdm(range(n_bootstrap)):\n",
    "    # Make a bootstrap sample of size bootstrap_size\n",
    "    set_seed(SEED + i)\n",
    "\n",
    "    indices_per_country = [np.where(preprocessor.country_train == c)[0] for c in np.unique(preprocessor.country_train)]\n",
    "    bootstrap_idx = np.concatenate([np.random.choice(indices, size=bootstrap_size, replace=True) for indices in indices_per_country])\n",
    "    x_train_bootstrap = X_train[bootstrap_idx]\n",
    "    y_train_bootstrap = y_train[bootstrap_idx]\n",
    "\n",
    "    model_bootstrap, _, _, _ = train_nn(x_train_bootstrap, y_train_bootstrap, X_valid, y_valid, num_epochs=100, learning_rate=5e-4, weight_decay=7e-2, verbose=False)\n",
    "    y_pred = model_bootstrap(torch.tensor(X_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rsquared = compute_rsquared(y_valid, y_pred)\n",
    "\n",
    "    bootstrap_models.append(model_bootstrap)\n",
    "    mse_bootstrap[i] = mse\n",
    "    rsquared_bootstrap[i] = rsquared\n",
    "\n",
    "# Aggregate the predictions\n",
    "y_pred = np.zeros((X_valid.shape[0], n_bootstrap))\n",
    "for i in range(n_bootstrap):\n",
    "    y_pred[:, i] = bootstrap_models[i](torch.tensor(X_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()\n",
    "\n",
    "y_pred_mean = np.mean(y_pred, axis=1)\n",
    "y_pred_std = np.std(y_pred, axis=1)\n",
    "y_pred_median = np.median(y_pred, axis=1)\n",
    "\n",
    "# Get the model with the best R squared\n",
    "best_model_idx = np.argmax(rsquared_bootstrap)\n",
    "best_model = bootstrap_models[best_model_idx]\n",
    "best_rsquared = rsquared_bootstrap[best_model_idx]\n",
    "y_pred_best = best_model(torch.tensor(X_valid, dtype=torch.float32).to(device)).cpu().detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(mse_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the r squared\n",
    "bootstrapped_r2 = compute_rsquared(y_valid, y_pred_mean)\n",
    "bootstrapped_mse = mean_squared_error(y_valid, y_pred_mean)\n",
    "bootstrapped_mape = np.mean(np.abs((y_valid - y_pred_mean) / y_valid)) * 100\n",
    "print(f\"Bootstrapped R^2: {bootstrapped_r2}\")\n",
    "print(f\"Bootstrapped MSE: {bootstrapped_mse}\")\n",
    "print(f\"Bootstrapped MAPE: {bootstrapped_mape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.histplot(rsquared_bootstrap, bins=30, kde=True)\n",
    "plt.xlabel(\"R squared\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions per country, per date\n",
    "def plot_by_country(selected_country, country_valid):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(y_valid[country_valid == selected_country], label=\"True\")\n",
    "    plt.plot(y_pred_mean[country_valid == selected_country], label=\"Predicted\")\n",
    "    plt.plot(y_pred_median[country_valid == selected_country], label=\"Predicted (median)\")\n",
    "    plt.plot(y_pred_best[country_valid == selected_country], label=\"Predicted (best)\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 3 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 3 * y_pred_std[country_valid == selected_country], alpha=0.05, color=\"red\")\n",
    "    plt.fill_between(np.arange(len(y_valid[country_valid == selected_country])), y_pred_mean[country_valid == selected_country] - 1.96 * y_pred_std[country_valid == selected_country], y_pred_mean[country_valid == selected_country] + 1.96 * y_pred_std[country_valid == selected_country], alpha=0.2)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"GDP\")\n",
    "    plt.title(f\"{selected_country}\")\n",
    "    plt.legend()\n",
    "\n",
    "interact(plot_by_country, selected_country=np.unique(preprocessor.country_valid), country_valid=widgets.fixed(preprocessor.country_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BASED ONLY ON THE FIRST MODEL !! NOT THE BOOTSTRAP MODELS\n",
    "\n",
    "# Get the predictions\n",
    "x_valid = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "x_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_pred = model(x_valid).clone().detach().cpu().numpy().squeeze()\n",
    "y_pred_train = model(x_train).clone().detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the result by country and add 'Set' column\n",
    "y_pred_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_valid,\n",
    "    'country': preprocessor.country_valid,\n",
    "    'y_pred': y_pred,\n",
    "    'y_true': y_valid,\n",
    "    'Set': 'Validation'\n",
    "})\n",
    "\n",
    "y_pred_train_country = pd.DataFrame({\n",
    "    'date': preprocessor.dates_train,\n",
    "    'country': preprocessor.country_train,\n",
    "    'y_pred': y_pred_train,\n",
    "    'y_true': y_train,\n",
    "    'Set': 'Training'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[predictions_melted[\"country\"] == selected_country]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None, style=\"Set\", markers=True\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together the train and the validation set\n",
    "predictions = pd.concat([y_pred_train_country, y_pred_country])\n",
    "\n",
    "# Melting the dataframe for better plotting\n",
    "predictions_melted = predictions.melt(\n",
    "    id_vars=[\"date\", \"country\", \"Set\"],\n",
    "    value_vars=[\"y_pred\", \"y_true\"], \n",
    "    var_name=\"Type\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Function to plot data for the selected country\n",
    "def plot_by_country(selected_country):\n",
    "    filtered_data = predictions_melted[(predictions_melted[\"country\"] == selected_country) & (predictions_melted[\"Set\"] == \"Validation\")]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=filtered_data,\n",
    "        x=\"date\", y=\"Value\", hue=\"Type\", errorbar = None\n",
    "    )\n",
    "    plt.title(f\"Prediction vs True Values for {selected_country}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Legend\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = predictions[\"country\"].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_by_country, selected_country=dropdown)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_column_to_column_diff(data, col_name, grouping_by, mode, diff_period=1, sort_by=None):\n",
    "    \"\"\"\n",
    "    Inverse of the _column_to_column_diff function.\n",
    "    Reconstructs the original column values from the computed differences or percentage changes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The data after applying _column_to_column_diff.\n",
    "    col_name : str\n",
    "        The name of the column that was modified by _column_to_column_diff.\n",
    "    grouping_by : str\n",
    "        The column to group by.\n",
    "    mode : str\n",
    "        The mode used in _column_to_column_diff ('diff' or 'pct').\n",
    "    diff_period : int\n",
    "        The period used in _column_to_column_diff.\n",
    "    sort_by : str\n",
    "        The column to sort the data by.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The data with the original column values reconstructed.\n",
    "    \"\"\"\n",
    "    if sort_by:\n",
    "        data.sort_values(sort_by, inplace=True)\n",
    "\n",
    "    # Check if initial values are available\n",
    "    initial_col_name = '_initial_' + col_name\n",
    "    if initial_col_name not in data.columns:\n",
    "        raise ValueError(f\"Initial values are required and should be stored in '{initial_col_name}'.\")\n",
    "\n",
    "    if mode == 'diff':\n",
    "        # Function to invert the diff operation for each group\n",
    "        def invert_diff(group):\n",
    "            # Initialize the reconstructed column with NaNs\n",
    "            reconstructed = pd.Series(index=group.index, dtype=group[col_name].dtype)\n",
    "            # Fill in the initial values\n",
    "            reconstructed.iloc[:diff_period] = group[initial_col_name].iloc[:diff_period]\n",
    "            # Compute the cumulative sum to reconstruct the original values\n",
    "            reconstructed.iloc[diff_period:] = (\n",
    "                group[col_name].iloc[diff_period:].cumsum() + reconstructed.iloc[diff_period - 1]\n",
    "            )\n",
    "            return reconstructed\n",
    "\n",
    "        # Apply the inversion to each group\n",
    "        data[col_name] = data.groupby(grouping_by, group_keys=False).apply(invert_diff)\n",
    "\n",
    "    elif mode == 'pct':\n",
    "        # Function to invert the pct_change operation for each group\n",
    "        def invert_pct(group):\n",
    "            # Initialize the reconstructed column with NaNs\n",
    "            reconstructed = pd.Series(index=group.index, dtype=group[col_name].dtype)\n",
    "            # Fill in the initial values\n",
    "            reconstructed.iloc[:diff_period] = group[initial_col_name].iloc[:diff_period]\n",
    "            # Compute the cumulative product to reconstruct the original values\n",
    "            reconstructed.iloc[diff_period:] = (\n",
    "                (group[col_name].iloc[diff_period:] + 1).cumprod() * reconstructed.iloc[diff_period - 1]\n",
    "            )\n",
    "            return reconstructed\n",
    "\n",
    "        # Apply the inversion to each group\n",
    "        data[col_name] = data.groupby(grouping_by, group_keys=False).apply(invert_pct)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'diff' or 'pct'.\")\n",
    "\n",
    "    # Drop the initial values column as it's no longer needed\n",
    "    data.drop(columns=[initial_col_name], inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gdps.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['date'] = pd.to_datetime(predictions['date'])\n",
    "all_gdps['date'] = pd.to_datetime(all_gdps['date'])\n",
    "\n",
    "predictions['y_pred'] = predictions['y_pred'] * (preprocessor.y_std - EPS) + preprocessor.y_mean\n",
    "predictions['y_true'] = predictions['y_true'] * (preprocessor.y_std - EPS) + preprocessor.y_mean\n",
    "\n",
    "all_gdps_merged_pred = predictions.merge(all_gdps, on=['country', 'date'], how='left')\n",
    "all_gdps_merged_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted\n",
    "all_gdps_merged_pred.sort_values(['country', 'date'], inplace=True)\n",
    "\n",
    "def reconstruct_gdp_pct(group):\n",
    "    group = group.sort_values('date').reset_index(drop=True)\n",
    "    predicted_gdp = []\n",
    "    for i in range(len(group)):\n",
    "        if i < 4:\n",
    "            predicted_gdp.append(group.loc[i, 'GDP'])\n",
    "        else:\n",
    "            # Predicted GDP = Previous Predicted GDP * (1 + Predicted Percentage Change)\n",
    "            pred_gdp = group.loc[i -4, 'GDP'] * (1 + group.loc[i, 'y_true'])\n",
    "            predicted_gdp.append(pred_gdp)\n",
    "    group['predicted_GDP'] = predicted_gdp\n",
    "    return group\n",
    "\n",
    "# Apply the reconstruction function\n",
    "all_gdps_merged_pred_reconstructed = all_gdps_merged_pred.groupby('country', group_keys=False).apply(reconstruct_gdp_pct)\n",
    "\n",
    "# View the result\n",
    "print(all_gdps_merged_pred_reconstructed[['date', 'country', 'GDP', 'y_pred', 'predicted_GDP']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for a specific country\n",
    "def plot_reconstructed_gdp(selected_country):\n",
    "    # Filter the data for the selected country\n",
    "    country_data = all_gdps_merged_pred_reconstructed[all_gdps_merged_pred_reconstructed['country'] == selected_country]\n",
    "    \n",
    "    # Plot the actual and predicted GDP\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(country_data['date'], country_data['GDP'], label='Actual GDP')\n",
    "    plt.plot(country_data['date'], country_data['predicted_GDP'], label='Predicted GDP')\n",
    "    plt.title(f'Actual vs Predicted GDP for {selected_country}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('GDP')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting the country\n",
    "countries = all_gdps_merged_pred_reconstructed['country'].unique()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value=countries[0],\n",
    "    description='Country:'\n",
    ")\n",
    "\n",
    "# Use the interact function to link the dropdown with the plot function\n",
    "interact(plot_reconstructed_gdp, selected_country=dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gdps_merged_pred_reconstructed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
